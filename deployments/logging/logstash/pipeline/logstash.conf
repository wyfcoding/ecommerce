input {
  # 从 Kafka 读取日志
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["app-logs", "access-logs", "error-logs"]
    codec => json
    group_id => "logstash-consumer"
    auto_offset_reset => "latest"
  }
  
  # 从文件读取日志（备用）
  file {
    path => "/var/log/ecommerce/*.log"
    start_position => "beginning"
    codec => json
    type => "file"
  }
}

filter {
  # 解析 JSON 日志
  if [message] {
    json {
      source => "message"
      target => "parsed"
    }
  }
  
  # 添加地理位置信息
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
      database => "/usr/share/logstash/GeoLite2-City.mmdb"
    }
  }
  
  # 解析 User-Agent
  if [user_agent] {
    useragent {
      source => "user_agent"
      target => "ua"
    }
  }
  
  # 添加时间戳
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }
  }
  
  # 添加服务标签
  mutate {
    add_field => {
      "[@metadata][index_prefix]" => "ecommerce"
    }
  }
  
  # 根据日志级别添加标签
  if [level] {
    if [level] == "ERROR" or [level] == "FATAL" {
      mutate {
        add_tag => ["error"]
      }
    } else if [level] == "WARN" {
      mutate {
        add_tag => ["warning"]
      }
    }
  }
}

output {
  # 输出到 Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_prefix]}-logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }
  
  # 错误日志单独索引
  if "error" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "ecommerce-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # 调试输出（开发环境）
  # stdout {
  #   codec => rubydebug
  # }
}
